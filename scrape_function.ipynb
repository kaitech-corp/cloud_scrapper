{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@shriftman/the-building-blocks-of-generative-ai-a75350466a2f?source=tag_recommended_feed---------2-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@odsc?source=tag_recommended_feed---------0-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@mkr.2096/exploring-the-essentials-of-generative-ai-mathematics-and-practical-applications-18c9b829caf7?source=tag_recommended_feed---------3-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/the-generator/this-obscure-french-philosophers-masterwork-suggests-chatgpt-may-be-alive-697185c0d632?source=tag_recommended_feed---------4-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@jrodthoughts?source=tag_recommended_feed---------8-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/business\n",
      "https://medium.com/@tomsmith585?source=tag_recommended_feed---------4-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@onkarmishra?source=tag_recommended_feed---------5-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@sidbhat?source=tag_recommended_feed---------6-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@phlip007?source=tag_recommended_feed---------1-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@shriftman?source=tag_recommended_feed---------2-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e\n",
      "https://medium.com/@phlip007/the-problem-of-a-generation-ae1336a68d16?source=tag_recommended_feed---------1-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/towards-data-science/legal-and-ethical-perspectives-on-generative-ai-5e7ba2308469?source=tag_recommended_feed---------7-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@mkr.2096?source=tag_recommended_feed---------3-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed?source=tag_recommended_feed---------5-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@priyanka.boddapati/generative-ai-made-accessible-an-in-depth-breakdown-of-googles-free-introduction-to-generative-1b13aa9e4633?source=tag_recommended_feed---------9-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@jrodthoughts/meet-opro-google-deepminds-new-method-that-optimizes-prompts-better-than-humans-4b840655b995?source=tag_recommended_feed---------8-85----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/tag/generative-ai\n",
      "https://medium.com/@tanuwidjajaolivia?source=tag_recommended_feed---------7-107----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@odsc/announcing-the-new-generative-ai-fundamentals-certificate-491e85fc7eab?source=tag_recommended_feed---------0-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@sidbhat/comparing-anthropic-claude2-with-open-ai-chat-gpt-4-88b31f3aea9a?source=tag_recommended_feed---------6-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n",
      "https://medium.com/@priyanka.boddapati?source=tag_recommended_feed---------9-84----------generative_ai----------5d7633ea_016f_4653_ada7_ba4055833cff-------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_duplicates(input_list):\n",
    "    # Create a set from the input list to remove duplicates\n",
    "    unique_set = set(input_list)\n",
    "    # Convert the set back to a list\n",
    "    unique_list = list(unique_set)\n",
    "    return unique_list\n",
    "\n",
    "def remove_items_with_substring(input_list, substring):\n",
    "    # Use a list comprehension to filter out items with the substring\n",
    "    filtered_list = [item for item in input_list if substring not in item]\n",
    "    return filtered_list\n",
    "\n",
    "substring_to_remove = \"https://medium.comhttps://\"\n",
    "\n",
    "def scrape_blog_urls(base_url, num_pages=10):\n",
    "    blog_urls = []\n",
    "    \n",
    "    for page_number in range(1, num_pages + 1):\n",
    "        # page_url = f\"{base_url}/page/{page_number}\"\n",
    "        response = requests.get(base_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Assuming that the blog post URLs are in anchor (a) tags with a specific class\n",
    "            post_links = soup.find_all('a', class_='af ag ah ai aj ak al am an ao ap aq ar as at')\n",
    "            \n",
    "            for link in post_links:\n",
    "                blog_urls.append(\"https://medium.com\" + link['href'])\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from page {page_number}. Status Code: {response.status_code}\")\n",
    "    \n",
    "    return blog_urls\n",
    "\n",
    "# Specify the base URL of the blog\n",
    "base_blog_url = \"https://medium.com/tag/generative-ai/recommended\"\n",
    "\n",
    "# Specify the number of pages to scrape (default is 10)\n",
    "num_pages_to_scrape = 1\n",
    "\n",
    "# Call the function to scrape blog URLs\n",
    "blog_urls = scrape_blog_urls(base_blog_url, num_pages_to_scrape)\n",
    "filtered_list = remove_items_with_substring(blog_urls, substring_to_remove)\n",
    "blog_urls_cleaned = remove_duplicates(filtered_list)\n",
    "# Print the scraped blog URLs\n",
    "for url in blog_urls_cleaned:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" rel=\"noopener follow\" href=\"/@whojatingarg/opentofu-a-game-changing-evolution-in-infrastructure-as-code-abcf3bbb740d?source=tag_recommended_feed---------0-84----------iac----------22a22ee2_4629_4c32_bacc_bc407b3d01b7-------\"><h2 class=\"be nt lc ld nu nv le lf lg nw nx lh li lj tq tr lk ll lm ts tt ln lo lp tu tv lq cl nc nd nf nh bj\">OpenTofu: A Game-Changing Evolution in Infrastructure as Code</h2><div class=\"ok\"><h3 class=\"be b ol z cl om nc nd on nf nh ga\">In the ever-evolving world of cloud computing and DevOps, the name Terraform has long held sway as the go-to tool for automatingâ€¦</h3></div></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_blog_urls(base_url, num_pages=10):\n",
    "    blog_urls = []\n",
    "    \n",
    "    for page_number in range(1, num_pages + 1):\n",
    "        page_url = f\"{base_url}/page/{page_number}\"\n",
    "        response = requests.get(page_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <div> elements with class \"u2M0Kb\"\n",
    "            div_elements = soup.find_all('div', class_='u2M0Kb')\n",
    "            \n",
    "            for div in div_elements:\n",
    "                # Within each <div>, find the first <a> tag and get the \"href\" attribute\n",
    "                a_tag = div.find('a')\n",
    "                if a_tag and 'href' in a_tag.attrs:\n",
    "                    blog_url = a_tag['href']\n",
    "                    blog_urls.append(blog_url)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from page {page_number}. Status Code: {response.status_code}\")\n",
    "    \n",
    "    return blog_urls\n",
    "\n",
    "# Specify the base URL of the blog\n",
    "base_blog_url = \"https://neptune.ai/blog\"\n",
    "\n",
    "# Specify the number of pages to scrape (default is 10)\n",
    "num_pages_to scrape = 10\n",
    "\n",
    "# Call the function to scrape blog URLs\n",
    "blog_urls = scrape_blog_urls(base_blog_url, num_pages_to_scrape)\n",
    "\n",
    "# Print the scraped blog URLs\n",
    "for url in blog_urls:\n",
    "    print(url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
